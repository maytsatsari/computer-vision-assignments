{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSeTBbol7LHT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import types\n",
        "# Thisisabitofmagictomakematplotlibfiguresappearinlineinthenotebook\n",
        "# ratherthaninanewwindow.\n",
        "%matplotlib inline\n",
        "# editthislinetochangethefiguresize\n",
        "plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
        "plt.rcParams['font.size'] = 16\n",
        "# forceauto-reloadofimportmodulesbeforerunningcode\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMdLIyT5w-Sa"
      },
      "source": [
        "## Ζήτημα 1.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM9veDTQ8RYa",
        "outputId": "a6b04818-f56d-4e9f-de15-883da5c23341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: curl [options...] <url>\n",
            " -d, --data <data>          HTTP POST data\n",
            " -f, --fail                 Fail silently (no output at all) on HTTP errors\n",
            " -h, --help <category>      Get help for commands\n",
            " -i, --include              Include protocol response headers in the output\n",
            " -o, --output <file>        Write to file instead of stdout\n",
            " -O, --remote-name          Write output to a file named as the remote file\n",
            " -s, --silent               Silent mode\n",
            " -T, --upload-file <file>   Transfer local FILE to destination\n",
            " -u, --user <user:password> Server user and password\n",
            " -A, --user-agent <name>    Send User-Agent <name> to server\n",
            " -v, --verbose              Make the operation more talkative\n",
            " -V, --version              Show version number and quit\n",
            "\n",
            "This is not the full help, this menu is stripped into categories.\n",
            "Use \"--help category\" to get an overview of all categories.\n",
            "For all options use the manual or \"--help all\".\n",
            "mkdir: invalid option -- 'd'\n",
            "Try 'mkdir --help' for more information.\n"
          ]
        }
      ],
      "source": [
        "!curl -Ohttp://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!mkdir -pdata && tar-xzvfcifar-10-python.tar.gz--directorydata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeJEIds8XtmV"
      },
      "source": [
        "### data_util.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJpM5Jl8g53"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "  \"\"\"\n",
        "  Load a batch of images from the CIFAR10 python dataset\n",
        "  \"\"\"\n",
        "  fh = open(filename, 'rb')\n",
        "  data_dict = pickle.load(fh, encoding='latin1')\n",
        "  X = data_dict['data'].reshape(10000,3,32,32).transpose(0,2,3,1)\n",
        "  X = X.astype(\"float\")/255.0\n",
        "  Y = np.array(data_dict['labels'])\n",
        "  fh.close()\n",
        "  return X, Y\n",
        "\n",
        "def load_CIFAR10(data_dir):\n",
        "  \"\"\"\n",
        "  Load entire CIFAR10 python dataset\n",
        "  \"\"\"\n",
        "  X_list = []\n",
        "  Y_list = []\n",
        "  for b in range(1,6):\n",
        "    filename = os.path.join(data_dir, 'data_batch_%d' % (b, ))\n",
        "    X_b, Y_b = load_CIFAR_batch(filename)\n",
        "    X_list.append(X_b)\n",
        "    Y_list.append(Y_b)\n",
        "  X_train = np.concatenate(X_list)\n",
        "  Y_train = np.concatenate(Y_list)\n",
        "  X_test, Y_test = load_CIFAR_batch(os.path.join(data_dir, 'test_batch'))\n",
        "  return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def get_CIFAR10_data(num_train=49000, num_valid=1000, num_test=1000):\n",
        "  \"\"\"\n",
        "  Load CIFAR10 dataset and assign train, test and val splits\n",
        "  (total training data = 50k, test = 10k)\n",
        "  \"\"\"\n",
        "  data_dir = r'C:\\Users\\mayts\\Desktop\\cifar-10-batches-py'\n",
        "  X_train, Y_train, X_test, Y_test = load_CIFAR10(data_dir)\n",
        "\n",
        "  X_val = X_train[num_train:(num_train+num_valid)]\n",
        "  Y_val = Y_train[num_train:(num_train+num_valid)]\n",
        "  X_train = X_train[0:num_train]\n",
        "  Y_train = Y_train[0:num_train]\n",
        "  X_test = X_test[0:num_test]\n",
        "  Y_test = Y_test[0:num_test]\n",
        "\n",
        "  return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
        "\n",
        "# allow accessing these functions by data_util.*\n",
        "data_util=types.SimpleNamespace()\n",
        "data_util.load_CIFAR_batch=load_CIFAR_batch\n",
        "data_util.load_CIFAR10=load_CIFAR10\n",
        "data_util.get_CIFAR10_data=get_CIFAR10_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeRTdRYX-Wg"
      },
      "source": [
        "### im_util.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSZnf_c2YCsQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def remove_ticks(ax):\n",
        "  \"\"\"\n",
        "  Remove axes tick labels\n",
        "  \"\"\"\n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "\n",
        "def plot_classification_examples(Y_hat,Y_test,im,names):\n",
        "  \"\"\"\n",
        "  Plot sample images with predictions Y_hat and true labels Y_test\n",
        "  \"\"\"\n",
        "  fh = plt.figure()\n",
        "  num_test=Y_test.size\n",
        "  for i in range(10):\n",
        "    r = np.random.randint(num_test)\n",
        "    ax=plt.subplot(1,10,i+1)\n",
        "    remove_ticks(ax)\n",
        "    lh=plt.xlabel(names[Y_hat[r]])\n",
        "    if (Y_hat[r]==Y_test[r]):\n",
        "      lh.set_color('green')\n",
        "    else:\n",
        "      lh.set_color('red')\n",
        "    plt.imshow(im[r])\n",
        "\n",
        "def plot_weights(W, names):\n",
        "  \"\"\"\n",
        "  Plot images for each weight vector in W\n",
        "  \"\"\"\n",
        "  fh = plt.figure()\n",
        "  for i in range(10):\n",
        "    W_im = np.reshape(W[:,i],(32,32,3))\n",
        "    W_im = normalise_01(W_im)\n",
        "    ax=plt.subplot(1,10,i+1)\n",
        "    remove_ticks(ax)\n",
        "    plt.xlabel(names[i])\n",
        "    plt.imshow(W_im)\n",
        "\n",
        "def normalise_01(im):\n",
        "  \"\"\"\n",
        "  Normalise image to the range (0,1)\n",
        "  \"\"\"\n",
        "  mx = im.max()\n",
        "  mn = im.min()\n",
        "  den = mx-mn\n",
        "  small_val = 1e-9\n",
        "  if (den < small_val):\n",
        "    print('image normalise_01 -- divisor is very small')\n",
        "    den = small_val\n",
        "  return (im-mn)/den\n",
        "\n",
        "# allow accessing these functions by im_util.*\n",
        "im_util=types.SimpleNamespace()\n",
        "im_util.remove_ticks=remove_ticks\n",
        "im_util.plot_classification_examples=plot_classification_examples\n",
        "im_util.plot_weights=plot_weights\n",
        "im_util.normalise_01=normalise_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txqGH2jiYYnl"
      },
      "outputs": [],
      "source": [
        "\"\"\"Load CIFAR10 data\"\"\"\n",
        "\n",
        "\n",
        "num_classes=10\n",
        "num_dims=32*32*3\n",
        "\n",
        "cifar10_names=['airplane', 'automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "num_train=49000\n",
        "num_valid=1000\n",
        "num_test=10000\n",
        "\n",
        "im_train,Y_train,im_valid,Y_valid,im_test,Y_test = data_util.get_CIFAR10_data(num_train,num_valid,num_test)\n",
        "\n",
        "X_train=np.reshape(im_train,(num_train,num_dims))\n",
        "X_valid=np.reshape(im_valid,(num_valid,num_dims))\n",
        "X_test=np.reshape(im_test,(num_test,num_dims))\n",
        "\n",
        "print('X_train shape = ',X_train.shape)  # 3072 = num_dims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC7gV6fNikBP"
      },
      "source": [
        "### Οπτικοποίηση μέσης εικόνας κάθε κατηγορίας\n",
        "Για το κομμάτι κώδικα που έπρεπε να συμπληρώσουμε. Σύνοψη:Υπολόγισα τη μέση εικόνα για κάθε τάξη, επαναλήφθηκε σε κάθε συγκεκριμένη κατηγορία και βρήκα τα δείγματα εικόνων που ανήκουν σε αυτήν την κατηγορία\n",
        "τελικά μέσος όρος των εικόνων κατά μήκος του άξονα 0 και προσάρτηση του προκύπτοντος στη λίστα avg_im."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1MZpP5PijEB"
      },
      "outputs": [],
      "source": [
        "\"\"\"Visualise average image\"\"\"\n",
        "\n",
        "avg_im = []\n",
        "\n",
        "# base code: use first image of each class\n",
        "for i in range(10):\n",
        "    j = next(k for k in range(num_train) if Y_train[k]==i)\n",
        "    avg_im.append(im_train[j])\n",
        "\n",
        "\"\"\" Remove the first 10 images from avg_im. This step is necessary because the first 10 images are incorrectly added\n",
        "to the avg_im array due to the execution of the algorithm that computes the average image for each class.\"\"\"\n",
        "avg_im = avg_im[10:]\n",
        "\n",
        "# the np.where, np.mean, im_train ... is from library NumPy\n",
        "# Compute the average image for each class and store in avg_im\n",
        "for i in range(num_classes):\n",
        "  #Finds the sample images that match the current class.\n",
        "    idx = np.where(Y_train == i)[0]\n",
        "    #Calculates the average of the images for the current class and stores it in the avg_im array.\n",
        "    avg_im.append(np.mean(im_train[idx], axis=0))\n",
        "\n",
        "for i in range(10):\n",
        "    ax=plt.subplot(1,10,i+1)\n",
        "    im_util.remove_ticks(ax)\n",
        "    plt.xlabel(cifar10_names[i])\n",
        "    plt.imshow(avg_im[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w_61Hg1xA4K"
      },
      "source": [
        "## Ζήτημα 1.2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7jmAGejzKBG"
      },
      "source": [
        "Στην ερώτηση 1.2, υπολογίζουμε πρώτα τον μέσο όρο των εικόνων για κάθε τάξη, με βάση το σετ εκπαίδευσης. Στη συνέχεια, για κάθε εικόνα στο σύνολο δοκιμής, υπολογίζουμε το τετράγωνο της απόστασης μεταξύ αυτής και της μέσης εικόνας κάθε κατηγορίας. Τέλος, προβλέπουμε την κλάση εικόνας ως αυτή με τη μικρότερη απόσταση. Αυτή η λειτουργία επιτρέπει την κατηγοριοποίηση των δοκιμαστικών εικόνων με βάση τον μέσο όρο των εικόνων κάθε κατηγορίας."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6Zuq9q9xGKH"
      },
      "outputs": [],
      "source": [
        "\"\"\"Nearest Mean Classifier\"\"\"\n",
        "\n",
        "#FORNOW: random labels\n",
        "Y_hat=np.random.randint(0,10,num_test)\n",
        "\n",
        "\n",
        "# Compute the squared distance between two images\n",
        "def squared_distance(image1, image2):\n",
        "    return np.sum((image1 - image2) ** 2)\n",
        "\n",
        "# Nearest Mean Classifier\n",
        "\"\"\"\n",
        "*****************************************************\n",
        "\"\"\"\n",
        "Y_hat = np.zeros(num_test, dtype=int)\n",
        "\n",
        "for i in range(num_test):\n",
        "    # Calculation of the distances from the average values ​​of the classes\n",
        "    distances = [squared_distance(im_test[i], avg_im[j]) for j in range(num_classes)]\n",
        "\n",
        "    # Find the class with the minimum distance and store it in Y_hat\n",
        "    Y_hat[i] = np.argmin(distances)\n",
        "\n",
        "nm_accuracy=np.sum(Y_hat==Y_test)/num_test\n",
        "im_util.plot_classification_examples(Y_hat.astype(int),Y_test,im_test,cifar10_names)\n",
        "\n",
        "print('Nearest mean classifier accuracy = %.2f%%' % (100.0*nm_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5Z7goC0NAt"
      },
      "source": [
        "## Ζήτημα 1.3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfW8huvX0PzO"
      },
      "outputs": [],
      "source": [
        "\"\"\"Nearest Neighbour Classifier\"\"\"\n",
        "def compute_distances(desc1, desc2):\n",
        "    \"\"\"\n",
        "    Compute Euclidean distances between descriptors\n",
        "\n",
        "    Inputs: desc1=descriptor array (N1, num_dims)\n",
        "            desc2=descriptor array (N2, num_dims)\n",
        "\n",
        "    Returns: dists=array of distances (N1,N2)\n",
        "    \"\"\"\n",
        "    N1,num_dims=desc1.shape\n",
        "    N2,num_dims=desc2.shape\n",
        "\n",
        "    ATB=np.dot(desc1,desc2.T)\n",
        "    AA=np.sum(desc1*desc1,1)\n",
        "    BB=np.sum(desc2*desc2,1)\n",
        "\n",
        "    dists = -2*ATB + np.expand_dims(AA,1) + BB\n",
        "\n",
        "    return dists\n",
        "\n",
        "\n",
        "num_test_small=1000\n",
        "X_test_small=X_test[0:num_test_small]\n",
        "Y_test_small=Y_test[0:num_test_small]\n",
        "\n",
        "Y_hat=np.random.randint(0,10,num_test_small)\n",
        "\n",
        "\"\"\"\n",
        "*****************************************************\n",
        "\"\"\"\n",
        "distances = compute_distances(X_test_small, X_train)\n",
        "for i in range(num_test_small):\n",
        "  # We match the class of the test image to the class of the closest training image.\n",
        "    Y_hat[i] = Y_train[np.argmin(distances[i])]\n",
        "\n",
        "\n",
        "nn_accuracy=np.sum(Y_hat==Y_test_small)/num_test_small\n",
        "print('Nearest neighbour classifier accuracy =% .2f%%' % (100.0*nn_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2rpF9te1B0D"
      },
      "source": [
        "### Σχολιασμός αποτελέσματος Nearest neighbor σε σχέση με Nearest Mean Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95Irv2z1EY_"
      },
      "source": [
        "Ενώ ο πλησιέστερος μέσος ταξινομητής εστιάζει αποκλειστικά στην ταξινόμηση νέων παραδειγμάτων με βάση τις αποστάσεις από τον μέσο όρο κάθε τάξης εκπαίδευσης, αγνοώντας τη διακύμανση και το σχήμα των πραγματικών κατανομών δεδομένων, η προσέγγιση του Πλησιέστερου Γείτονα εξετάζει τα πλήρη δεδομένα εκπαίδευσης λεπτομερώς για να κάνει προβλέψεις. Λαμβάνοντας υπόψη όλες τις διαθέσιμες πληροφορίες από κάθε σημείο εκπαίδευσης και όχι απλώς τους μέσους όρους, το Nearest Neighbor είναι καλύτερα σε θέση να αντικατοπτρίζει σύνθετες, διαφοροποιημένες σχέσεις στον χώρο χαρακτηριστικών και ως εκ τούτου να δημιουργεί πιο ακριβείς, αντιπροσωπευτικές αποφάσεις που ευθυγραμμίζονται πιο στενά με την πραγματική δομή των δεδομένων . Μέσω ενός πιο ολοκληρωμένου χειρισμού του πλήρους χαρακτήρα του δείγματος εκπαίδευσης, το Nearest Neighbor ξεπερνά την περιορισμένη, αφηρημένη προβολή του Nearest Mean και παρέχει ως αποτέλεσμα ανώτερη προγνωστική ακρίβεια."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oypi-rPI44B_"
      },
      "source": [
        "## Ζήτημα 1.4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFDJAiq65PA0"
      },
      "outputs": [],
      "source": [
        "\"\"\"Linear Classifier\"\"\"\n",
        "\n",
        "\n",
        "def one_hot(Y, num_classes):\n",
        "    \"\"\"convert class labels to one-hot vector\"\"\"\n",
        "    num_train=Y.size\n",
        "    T = np.zeros((num_train, num_classes))\n",
        "    T[np.arange(num_train), Y]=1\n",
        "    return T\n",
        "\n",
        "\"\"\"\n",
        "*****************************************************\n",
        "\"\"\"\n",
        "# Fit a linear classifier to the CIFAR10 data\n",
        "# Convert the class labels to binary\n",
        "T_train = one_hot(Y_train, num_classes)\n",
        "# We apply linear regression to train the classifier\n",
        "# We use the lstsq method of numpy to find the weights W of the classifier as we have been asked by the statement of the exercise\n",
        "W, _, _, _ = np.linalg.lstsq(X_train, T_train, rcond=None)\n",
        "\n",
        "\n",
        "\n",
        "# predict labels on the test set using W\n",
        "\n",
        "T_hat = np.dot(X_test,W)\n",
        "Y_hat = np.argmax(T_hat,1)\n",
        "\n",
        "lin_accuracy=np.sum(Y_hat==Y_test)/num_test\n",
        "\n",
        "print('Linear classifier accuracy =% .2f%%' % (100.0*lin_accuracy))\n",
        "\n",
        "# visualise the linear weights\n",
        "im_util.plot_weights(W, cifar10_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB7si4eC7TTY"
      },
      "source": [
        "\"Σχολιασμός οπτικοποίησης βαρών...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwrl_PFL7dr_"
      },
      "source": [
        "Οπτικοποίηση των βαρών του γραμμικού ταξινομητή ως εικόνες. Τα βάρη που μαθαίνονται από τον γραμμικό ταξινομητή μπορούν να απεικονιστούν ως μοτίβα που αντιπροσωπεύουν κάθε τάξη. Τα μοτίβα δείχνουν τις σημαντικές περιοχές των εικόνων που χρησιμοποιεί ο ταξινομητής για να κάνει τις προβλέψεις του. Για παράδειγμα, η κατηγορία μπορεί να περιλαμβάνει εικόνες με δεδομένο χρώμα ή σχήμα και αυτό θα είναι ορατό στις εικόνες βάρους."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDL-msKR8fAM"
      },
      "source": [
        "## Ζήτημα 1.5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFa0JlZl8ir-"
      },
      "outputs": [],
      "source": [
        "\"\"\"Regularised Linear Classifier\"\"\"\n",
        "\n",
        "\n",
        "def one_hot(Y, num_classes):\n",
        "  num_train = Y.size\n",
        "  T = np. zeros((num_train, num_classes))\n",
        "  T[np. arange(num_train), Y] = 1\n",
        "  return T\n",
        "\n",
        "lamda = 1.0\n",
        "\n",
        "T_train = one_hot(Y_train, num_classes)\n",
        "\n",
        "# we add the normalization term and this will help us to solve the linear system\n",
        "#This constant is added on the diagonal of the array X_train*T_train\n",
        "A = np.dot(X_train.T, X_train) + lamda * np.identity(num_dims)\n",
        "\n",
        "# that is derived from the multiplication of two matrices, X_train^T and T_train for the array B\n",
        "B = np. dot(X_train. T, T_train)\n",
        "\n",
        "# We use the function np.linalg.solve to solve the linear system AW = B\n",
        "W = np.linalg.solve(A, B)\n",
        "\"\"\"\n",
        "*****************************************************\n",
        "\"\"\"\n",
        "\n",
        "# compute accuracy on the test set\n",
        "\n",
        "def linear_classify(X,W,Y):\n",
        "  T_hat = np.dot(X,W)\n",
        "  Y_hat = np.argmax(T_hat,1)\n",
        "  accuracy = np.sum(Y_hat==Y)/np.size(Y)\n",
        "  return Y_hat, accuracy\n",
        "\n",
        "_,lin_accuracy=linear_classify(X_test,W,Y_test)\n",
        "\n",
        "print('Linear classifier accuracy =% .2f%%' % (100.0*lin_accuracy))\n",
        "\n",
        "# visualise the linear weights\n",
        "im_util.plot_weights(W, cifar10_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbRujVt7Ai_L"
      },
      "source": [
        "## Ζήτημα 1.6:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8aJ9GqZJLE2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib. pyplot as plt\n",
        "\n",
        "\n",
        "weights = W # The weights of the model\n",
        "X_val = X_valid # Validation data\n",
        "Y_val = Y_valid # Validation tags\n",
        "\n",
        "#Define a list of other values of λ (lambda)\n",
        "lambda_values = [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "# We train a model for each value of λ\n",
        "validation_accuracies = []\n",
        "for lamda in lambda_values:\n",
        "# Here we apply L2 normalization to the weights\n",
        " regularized_weights = weights / (1 + lamda)\n",
        "# What is the accuracy on the validation set?\n",
        "predictions = np. dot(X_val, regularized_weights)\n",
        "accuracy = np.mean((predictions > 0.5) == Y_val)\n",
        "validation_accuracies. append(accuracy)\n",
        "\n",
        "# We select the λ that produces the highest accuracy\n",
        "best_lambda = lambda_values[np. argmax(validation_accuracies)]\n",
        "print(f\"Best lambda: {best_lambda}\")\n",
        "\n",
        "# To assess the model, we apply it to the control set\n",
        "test_predictions = np. dot(X_test, weights / (1 + best_lambda))\n",
        "test_accuracy = np.mean((test_predictions > 0.5) == Y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:. 4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AHepGGJHoSD"
      },
      "source": [
        "\"Σχολιασμός της συμπεριφοράς του ταξινομητή καθώς μεταβάλετε το $\\lambda$ \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ggbNFFLHwZC"
      },
      "source": [
        "\n",
        "Η διαδικασία κανονικοποίησης ενισχύεται όταν το λ αυξάνεται και αυτό κάνει το μοντέλο να δίνει μικρότερα βάρη και να το κάνει λιγότερο σύνθετο. Αυτό μπορεί να είναι χρήσιμο για την αντιμετώπιση του προβλήματος της υπερεκπαίδευσης των δικτύων, αλλά αν το λ γίνει μεγάλο τότε το δίκτυο γίνεται πιο απλό να εκπαιδεύσει και να δοκιμάσει άλλα δίκτυα"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxzHiH-5IzMN"
      },
      "source": [
        "\"Ενδεικτικά αποτελέσματα για διάφορες τιμές του lamda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRnaLccYI2OQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yteBIm30LHBT"
      },
      "source": [
        "## Ζήτημα 1.7:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y88-bIyLPHj"
      },
      "outputs": [],
      "source": [
        "\"\"\"Linear Classifier by Stochastic Gradient Descent\"\"\"\n",
        "\n",
        "batch_size=32\n",
        "weight_decay=0.01 # same as lambda\n",
        "learning_rate=1e-2  # Play around with this hyperparameter until you improve validation accuracy.\n",
        "\n",
        "num_epochs=10\n",
        "num_iterations=num_epochs*(int)(num_train/batch_size)\n",
        "\n",
        "np.random.seed(42)\n",
        "W=np.random.randn(num_dims,num_classes)\n",
        "\n",
        "\n",
        "valid_acc_seq=[]\n",
        "iteration_seq=[]\n",
        "W_seq=[]\n",
        "W_sq_seq=[]\n",
        "\n",
        "summary_interval=1000\n",
        "\n",
        "\n",
        "for i in range(num_iterations):\n",
        "\n",
        "    batch_indices = np.random.choice(num_train, batch_size)\n",
        "    X_batch = X_train[batch_indices]\n",
        "    Y_batch = Y_train[batch_indices]\n",
        "    T_batch = one_hot(Y_batch, num_classes)\n",
        "\n",
        "    # Calculate the gradient\n",
        "    prediction = np.dot(X_batch, W)\n",
        "    error = prediction - T_batch\n",
        "    gradient = np.dot(X_batch.T, error) / batch_size + 2 * weight_decay * W\n",
        "\n",
        "    W = W + dW\n",
        "\n",
        "    if (i % summary_interval == 0):\n",
        "        _,valid_acc=linear_classify(X_valid,W,Y_valid)\n",
        "        valid_acc_seq.append(valid_acc)\n",
        "        iteration_seq.append(i)\n",
        "        print(' valid acc =% .2f%%' % (100.0 * valid_acc))\n",
        "        W_seq.append(W)\n",
        "        W_sq_seq.append(np.sum(W**2))\n",
        "\n",
        "# plot validation accuracy and weight trends\n",
        "plt.rcParams['figure.figsize'] = (16.0, 6.0)\n",
        "\n",
        "fig=plt.figure()\n",
        "plt.grid(True)\n",
        "plt.plot(iteration_seq,valid_acc_seq,'r')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('accuracy')\n",
        "plt.ylim(0,0.5)\n",
        "plt.legend(['valid'])\n",
        "\n",
        "fig=plt.figure()\n",
        "plt.grid(True)\n",
        "plt.plot(iteration_seq,np.log(W_sq_seq))\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('log |W|^2')\n",
        "\n",
        "# compute test accuracy\n",
        "Y_hat,test_acc=linear_classify(X_test,W,Y_test)\n",
        "print('\\ntest accuracy = %.2f%%' % (100.0*test_acc))\n",
        "im_util.plot_classification_examples(Y_hat,Y_test,im_test,cifar10_names)\n",
        "im_util.plot_weights(W,cifar10_names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
